# Web Server Enumeration

Not every enumeration technique needs to provide actionable results. In the initial information gathering phase, it is important to perform a variety of enumeration methods to get a complete picture of a system.






- `http` utility
- `lynx` CLI browser
- `browsh --startup-url http://[IP]/[FILE]` # see the website in the terminal



## Web server version quick enum
curl -I URL




Content Discovery:

- Find out about files and directories on the server
- `/robots.txt` (see <http://www.robotstxt.org/robotstxt.html>)
- `/sitemap.xml`
- `/.well-known/`
- `/README.txt`
- `CHANGELOG.md`
- `CHANGELOG.txt` ???
- `/.git`

seclists/Discovery/Web-Content
























## Metasploit

- auxiliary/scanner/http/http_version
- auxiliary/scanner/http/http_header
- auxiliary/scanner/http/robots_txt
- auxiliary/scanner/http/dir_scanner # Directory brute force
	set DICTIONARY /usr/share/metasploit-framework/data/wordlists/directory.txt
- auxiliary/scanner/http/files_dir # File brute force
- auxiliary/scanner/http/http_login # Login brute force
	if using PASS_FILE and USER_FILE, unset the USERPASS_FILE
	dictionary options besides the default:
	set USER_FILE /usr/share/metasploit-framework/data/wordlists/namelist.txt
	set PASS_FILE /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt

- auxiliary/scanner/http/apache_userdir_enum # identify valid users
- auxiliary/scanner/http/brute_dirs


### auxiliary/scanner/http/http_put
Tip: try differents PATH options, ex:
```
> set PATH /
> set PATH /data/

```


Example (write file on the target server. If the file is already exists it will overwrite it)
```
use auxiliary/scanner/http/http_put
set RHOSTS 192.111.169.3
set PATH /data
set FILENAME test.txt
set FILEDATA "Welcome To AttackDefense"
run
```
Then use wget and download the test.txt file and verify it:
```
wget http://192.111.169.3:80/data/test.txt
```

use DELETE method and delete the text.file
```
use auxiliary/scanner/http/http_put
set RHOSTS 192.111.169.3
set PATH /data
set FILENAME test.txt
set ACTION DELETE
run
```
Now if you try to download the same file from the same path. This time we should receive 404 error. i.e file not found. Because we have deleted it.





















## dirb

```
dirb http://[IP]

# Basic
dirb https://url/
# Custom Header
dirb http://url/ -H test:test
# Wordlist
dirb http://url/ /usr/share/wordlists/dirb/small.txt
# File Extensions
dirb http://url/ -X .php
# Username & password
dirb http://url/ -u <username:password>
```



## dirbuster
?



## gobuster
- <https://github.com/OJ/gobuster>

`-x`: specify extention. Example: `-x php,html,txt,bak`, `-x php,py,html`

`-t`: default is 10, we can reduce the amount of traffic setting to 5 for example

```



gobuster dir -u URL -w WORDLIST -t THREADS -x EXTENSION(S) -o OUTPUT_FILE
feroxbuster -u URL -t THREADS -w WORDLIST -x EXTENSION(S) -v -k -n -q -e -r -o OUTPUT_FILE




gobuster dir -u http://[IP] -w /usr/share/wordlists/dirb/common.txt -o [OUTPUT FILENAME] -x txt,pdf,config

gobuster dir --url [URL] --wordlist [WORDLIST FILE]
gobuster dir -q --url [URL] --wordlist [WORDLIST FILE]

gobuster dir -u http://$IP -w /usr/share/wordlists/dirb/common.txt -t 5

gobuster dir -u http://$IP -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -x php,sh,txt,cgi,html,js,css,py



gobuster dir -u http://greenhorn.htb:3000/ -w /usr/share/wordlists/dirb/common.txt -t 50 | tee gobuster.txt

```



### API

create file `pattern`:
```
{GOBUSTER}/v1
{GOBUSTER}/v2
```

```
gobuster dir -u http://192.168.50.16:5002 -w /usr/share/wordlists/dirb/big.txt -p 
pattern

gobuster dir -u http://offsecwp/ -w /usr/share/wordlists/dirb/big.txt -p pattern -b 404,301
```

Then inspect the results with cURL:
```
curl -i http://192.168.50.16:5002/users/v1
```

If it throws some usernames, try enumerating them:
```
gobuster dir -u http://192.168.50.16:5002/users/v1/admin/ -w /usr/share/wordlists/dirb/small.txt
```

And again inspect the results:
```
curl -i http://192.168.50.16:5002/users/v1/admin/password
```










## dirsearch

```

dirsearch --crawl -u $ip

dirsearch -u http://mailing.htb/ -x 403,404,400


dirsearch -e php -u http://pocsecurity.icu

dirsearch.py -e php -u https://example.com --exclude-status 403,401

dirsearch.py -l target.txt --deep-recursive

dirsearch --tor --crawl -u https://example.com --exclude-status 404 --deep-recursive --max-rate=5 -q --format=xml

```



## ffuf
- <https://github.com/ffuf/ffuf>
- <https://medium.com/@qaafqasim/mastering-ffuf-basic-and-advanced-commands-60e53bdbffc7>

`-fc` filter status code



```

ffuf -w <wordlist> -u http://board.htb/ -H "Host: FUZZ.board.htb" -ac
ffuf -w <wordlist> -u http://board.htb/ -H "User-Agent: [USER AGENT]" -ac

ffuf -w wordlist_location -u www.google.com/FUZZ -H "User-Agent: your_user_agent" -p '0.5-10' -t 100


ffuf -w /usr/share/seclists/Discovery/DNS/subdomains-top1million-20000.txt -H "Host: FUZZ.example.com" -u http://[IP] -fc 302

ffuf -u http://[IP]/FUZZ -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -e 
.txt,.php,.html,.htm


# recursion for in-depth subdirectory analysis
ffuf -w wordlist_location -u http://192.168.1.1/FUZZ -fc 301 --recursion --recursion-depth 2


```




## wfuzz
web application bruteforcer

- <https://wfuzz.readthedocs.io/en/latest/index.html>
- <https://otterhacker.github.io/Pentest/Tools/Wfuzz.html>


```
wfuzz -c -L --hh=1674 ???


# 1 Subdomain enumaration
wfuzz -c --hc 400,404 -t 200 --hl 9 -w subdomains-top1million-110000.txt -u http://permx.htb -H "Host: FUZZ.permx.htb"

# 2 Perform directory fuzzing on the discovered subdomain to find additional hidden paths.
wfuzz -c --hc 400,404 -t 200  -w subdomains-top1million-110000.txt -u http://lms.permx.htb/FUZZ


```










## nuclei

```

nuclei -u https://example.com -s critical,high,medium,low,info

```





## nikto
```
nikto -h http://$IP | tee nikto.log
nikto -host $IP -output out.txt -port 80

nikto -h example.com -ssl

```





## Nmap


```
sudo nmap -p80 --script=http-enum $ip
nmap -sV -p80 --script http-enum
nmap -sV -p80 --script http-enum --script-args http-methods.url-path=/webdav/
nmap -sV -p80 --script http-webdav-scan--script-args http-methods.url-path=/webdav/

```








## masscan

```
amass enum -brute -active -d example.com -o amass-output.txt
amass enum -active -d example.com | httpx -sc -td -title -silent -o httpx.txt
cat httpx.txt | sed 's/http:\/\/\|https:\/\/\|ftp:\/\///g'
```





## subfinder
```
subfinder -silent -all -d example.com | httpx -silent -sc
subfinder -silent -all -d example.com | httpx | nuclei -s critical,high,medium,low,info

```




